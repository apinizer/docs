---
title: "Dashboard"
description: "You can monitor the general status of API Proxies, view metrics created from log data. You can perform environment-based queries, perform live monitoring with automatic refresh feature, and analyze performance, traffic, and error metrics."
---

The Analytics Dashboard visualizes metrics created from log data of API Proxies within the project. The dashboard provides monitoring of API Proxy general status and performance analysis.

  <img
    src="/images/analytic/dashboard-overview.png" 
    alt="Dashboard Screen"
    width="1000"
    style={{ borderRadius: '0.5rem' }}
  />



<Warning>
Querying and analytical visualization of API Traffic in Apinizer Management Console is only possible by adding an [Elasticsearch Connector](/en/integrations/connection-management/elasticsearch-monitor) to the relevant environment.
</Warning>

<Info>
Since an API Proxy can be loaded into multiple [Environments](/en/concepts/core-concepts/what-is-environment), metrics are **queried based on environment**. Environment selection must be made from the top of the page.
</Info>

## Features

<CardGroup cols={2}>
  <Card title="General Status Monitoring" icon="gauge">
    You can view the general status of API Proxies, total request count, success/error rates
  </Card>
  <Card title="Performance Metrics" icon="chart-line">
    You can analyze response times, processing times, and backend performance metrics
  </Card>
  <Card title="Traffic Analysis" icon="chart-bar">
    You can monitor API traffic over time, detect peak periods
  </Card>
  <Card title="Error Tracking" icon="triangle-exclamation">
    You can monitor error rates, error types, and problematic endpoints
  </Card>
  <Card title="Automatic Refresh" icon="arrows-rotate">
    You can track metrics live by activating the page's automatic refresh feature
  </Card>
  <Card title="Environment-Based Filtering" icon="filter">
    You can view separate metrics for different environments
  </Card>
</CardGroup>

<Tip>
Metrics on the screen can be automatically refreshed using the **Automatic Refresh** option at the top of the page.
</Tip>

## Dashboard Metrics

The dashboard includes the following main metric categories:

### General Metrics

| Metric | Description |
|--------|----------|
| **Total Request Count** | Total number of API requests received in the selected time range |
| **Successful Request Count** | Requests returning with HTTP 2xx status code |
| **Failed Request Count** | Requests returning with HTTP 4xx and 5xx status code |
| **Success Rate** | Ratio of successful requests to total requests (%) |
| **Error Rate** | Ratio of failed requests to total requests (%) |
| **Average Response Time** | Average response time of all requests (ms) |

### Traffic Metrics

<CardGroup cols={2}>
  <Card title="Request Count Over Time" icon="chart-line">
    - Change in request count over time (line chart)
    - Detection of peak periods
    - Trend analysis
  </Card>
  <Card title="Request Distribution by API Proxy" icon="chart-pie">
    - Which API Proxies are used how much
    - Usage intensity comparison
    - Most used APIs
  </Card>
  <Card title="Request Distribution by Endpoint" icon="chart-bar">
    - Most called endpoints
    - Endpoint usage statistics
    - Call count ranking
  </Card>
  <Card title="HTTP Method Distribution" icon="code">
    - Usage rates of GET, POST, PUT, DELETE methods
    - Request counts by method
  </Card>
</CardGroup>

### Performance Metrics

<CardGroup cols={2}>
  <Card title="Average Response Time" icon="gauge">
    - Average response time of all requests
    - Change in response time over time
    - Performance trend analysis
  </Card>
  <Card title="Response Time Distribution" icon="chart-area">
    - Response times in different time ranges
    - P50, P95, P99 percentile values
    - Min/Max response times
  </Card>
  <Card title="Backend Performance" icon="server">
    - Response times of backend APIs
    - Backend connection times
    - Upstream performance metrics
  </Card>
  <Card title="Slowest Endpoints" icon="turtle">
    - Endpoints with highest response times
    - APIs requiring optimization
  </Card>
</CardGroup>

### Error Metrics

<CardGroup cols={2}>
  <Card title="Status Code Distribution" icon="circle-exclamation">
    - 2xx, 4xx, 5xx status code rates
    - Success/Error distribution (pie chart)
  </Card>
  <Card title="Error Types" icon="bug">
    - Authentication errors
    - Routing errors
    - Policy errors
    - Backend errors
  </Card>
  <Card title="APIs with Most Errors" icon="triangle-exclamation">
    - API Proxies with high error rates
    - Problematic endpoints
  </Card>
  <Card title="Error Rate Over Time" icon="chart-line">
    - Change in error rate over time
    - Detection of error spikes
  </Card>
</CardGroup>

### Client Metrics

<CardGroup cols={2}>
  <Card title="Most Active Clients" icon="users">
    - Clients sending most requests
    - Request counts by client
    - Analysis by Client IP/Key
  </Card>
  <Card title="Client Status Distribution" icon="user-check">
    - Success/error rates by client
    - Blocked/Throttled clients
  </Card>
</CardGroup>

## Automatic Refresh

The dashboard enables live tracking of metrics with the automatic refresh feature.

<Steps>
  <Step title="Activate Automatic Refresh Option">
    Select the refresh interval from the **Automatic Refresh** dropdown menu at the top of the page
  </Step>
  <Step title="Select Refresh Interval">
    - 10 seconds
    - 30 seconds
    - 1 minute
    - 5 minutes
  </Step>
  <Step title="Live Monitoring">
    Metrics on the screen are automatically refreshed at the selected interval
  </Step>
</Steps>

<Tip>
When automatic refresh is active, metrics continue to update at regular intervals until the page is changed.
</Tip>

<Warning>
Very short refresh intervals (10-30 seconds) can create additional load on Elasticsearch. Intervals of 1-5 minutes are recommended for production environments.
</Warning>

## Environment-Based Querying

Dashboard metrics are queried based on environment. Separate metrics are displayed for each environment.

### Environment Selection

<Steps>
  <Step title="Open Environment Dropdown">
    Open the environment selector dropdown at the top of the page
  </Step>
  <Step title="Select Relevant Environment">
    Select the environment you want to see metrics for (Development, Test, Production, etc.)
  </Step>
  <Step title="Metrics Load">
    Metrics for the selected environment are automatically loaded and displayed
  </Step>
</Steps>

<Info>
Different environments may be connected to different Elasticsearch connectors. If multiple Elasticsearch Connectors are defined, data from the **first** Elasticsearch Connector added in Apinizer Management Console is displayed.
</Info>

### Time Range Filtering

You can select a time range for metrics:

| Time Range | Description |
|---------------|----------|
| **Last 15 Minutes** | Ideal for real-time monitoring |
| **Last 1 Hour** | Short-term performance analysis |
| **Last 24 Hours** | Daily traffic analysis |
| **Last 7 Days** | Weekly trend analysis |
| **Last 30 Days** | Monthly usage statistics |
| **Custom Range** | Start and end date selection |

<Tip>
Short time ranges (15 minutes - 1 hour) are suitable for real-time monitoring, while long time ranges (7-30 days) are suitable for trend analysis and capacity planning.
</Tip>

## Metric Interpretation and Usage

You can monitor the health of your APIs by correctly interpreting dashboard metrics.

### Success Rate Interpretation

| Success Rate | Status | Recommended Actions |
|--------------|-------|---------------------|
| **> 99%** | Very Good | Continue normal monitoring |
| **95-99%** | Good | Monitor errors, make minor improvements |
| **90-95%** | Attention | Analyze error causes, plan fixes |
| **< 90%** | Critical | Immediate intervention required, perform detailed analysis |

### Response Time Interpretation

| Average Response Time | Status | Recommended Actions |
|-----------------------|-------|---------------------|
| **< 100ms** | Excellent | Maintain current performance |
| **100-500ms** | Good | Evaluate optimization opportunities |
| **500ms-2s** | Slow | Perform performance optimization |
| **> 2s** | Critical | Immediate optimization required, use cache |

### Traffic Analysis

**Peak Periods:**
- Which hours have heavy traffic?
- Which days receive more requests?
- Should capacity planning be done?

**Sudden Increases (Spikes):**
- Are there unexpected traffic increases?
- Is there suspicion of DDoS attack?
- Is rate limiting sufficient?

**Trend Changes:**
- Is traffic increasing / decreasing?
- Are there seasonal changes?
- How is the impact of new feature launch?

## Problem Detection and Resolution

You can detect and resolve common problems with the dashboard.

### High Error Rate

**Problem Detection:**
- Error rate above 5%
- High 4xx/5xx rate in Status Code Distribution
- Concentrated errors on specific endpoints

**Analysis Steps:**
1. Check the **APIs with Most Errors** metric
2. Filter failed requests from the [API Traffic](/en/analytic/api-traffic) page
3. Perform detailed error analysis with [Tracing](/en/analytic/tracing)

**Possible Solutions:**
- Backend API issues → Inform backend team
- Authentication errors → Check credentials
- Validation errors → Fix request format

### Slow Performance

**Problem Detection:**
- Average response time increased
- Problematic APIs in Slowest Endpoints list
- Low backend performance

**Analysis Steps:**
1. Review the **Slowest Endpoints** metric
2. Analyze policy performance with [Tracing](/en/analytic/tracing)
3. Check backend response times

**Possible Solutions:**
- Add cache policy
- Optimize database queries
- Adjust backend timeout values
- Optimize or remove slow policies

### Abnormal Traffic Increase

**Problem Detection:**
- Sudden and unexpected request increase
- Heavy requests from specific IPs
- Rate limit violations

**Analysis Steps:**
1. Detect spikes in the **Request Count Over Time** chart
2. Check the **Most Active Clients** metric
3. Examine suspicious requests with [API Traffic](/en/analytic/api-traffic)

**Possible Solutions:**
- Add rate limiting and throttling policies
- Apply IP blacklist/whitelist
- Activate DDoS protection

## Use Cases

### Scenario 1: Daily Operational Monitoring

**Purpose:** Check API health daily.

<Steps>
  <Step title="Perform Morning Check">
    - General metrics: Success rate, total request count
    - Were there any issues overnight?
  </Step>
  <Step title="Check Error Rate">
    - Is error rate at normal levels?
    - Are there new error types?
  </Step>
  <Step title="Review Performance Metrics">
    - Are response times normal?
    - Are there slowdowns?
  </Step>
  <Step title="Detect Abnormal Situations">
    - Unexpected traffic increases
    - New error spikes
  </Step>
</Steps>

**Recommended Settings:**
- Time Range: Last 24 Hours
- Automatic Refresh: 5 Minutes

### Scenario 2: Weekly Performance Analysis

**Purpose:** Weekly trend analysis and capacity planning.

<Steps>
  <Step title="Review Traffic Trends">
    - Did traffic increase / decrease?
    - Which days are busier?
  </Step>
  <Step title="Analyze Performance Changes">
    - Did response times change?
    - How is backend performance?
  </Step>
  <Step title="Identify Most Used APIs">
    - Which APIs are used most?
    - Is optimization needed?
  </Step>
  <Step title="Perform Capacity Planning">
    - Is current capacity sufficient?
    - Is scaling necessary?
  </Step>
</Steps>

**Recommended Settings:**
- Time Range: Last 7 Days
- Comparison: With previous week

### Scenario 3: Post-Incident Analysis

**Purpose:** Root cause analysis after a problem occurs.

<Steps>
  <Step title="Determine Problem Time">
    - Select custom time range (incident time)
    - Can spike or anomaly be seen?
  </Step>
  <Step title="Identify Affected APIs">
    - Which APIs were affected?
    - What was the error type?
  </Step>
  <Step title="Root Cause Analysis">
    - Backend problem?
    - Policy error?
    - Traffic increase?
  </Step>
  <Step title="Detailed Review with Tracing">
    - Examine problematic requests with [Tracing](/en/analytic/tracing)
    - At which step did the error occur?
  </Step>
</Steps>

**Recommended Settings:**
- Time Range: Custom (incident time ±1 hour)
- Focus: Error metrics and affected endpoints

## Best Practices

<CardGroup cols={2}>
  <Card title="Perform Regular Monitoring" icon="calendar-check">
    - Daily operational checks
    - Weekly trend analyses
    - Monthly capacity planning evaluation
  </Card>
  <Card title="Create Baseline" icon="chart-line">
    - Record normal performance metrics
    - Monitor deviations from baseline
    - Set alarm thresholds
  </Card>
  <Card title="Use Automatic Refresh" icon="arrows-rotate">
    - Automatic refresh for real-time monitoring
    - Appropriate refresh interval selection (1-5 minutes)
    - Consider Elasticsearch load
  </Card>
  <Card title="Environment-Based Monitoring" icon="layer-group">
    - Separate monitoring for each environment
    - Prioritize Production monitoring
    - Compare between environments
  </Card>
  <Card title="Learn Metric Interpretation" icon="graduation-cap">
    - Know success rate thresholds
    - Set response time expectations
    - Quickly detect abnormal situations
  </Card>
  <Card title="Use Detailed Analysis Tools" icon="magnifying-glass-chart">
    - Detect problems from Dashboard
    - Examine in detail with [API Traffic](/en/analytic/api-traffic)
    - Find root cause with [Tracing](/en/analytic/tracing)
  </Card>
</CardGroup>

## Limitations and Considerations

<Warning>
**Elasticsearch Connector Required:**
- An Elasticsearch Connector must be added to the environment for dashboard metrics to be displayed
- If there are multiple Elasticsearch Connectors, data from the first added connector is displayed
</Warning>

<Info>
**Data Freshness Time:**
- Metrics are created from data in Elasticsearch
- It may take a few seconds for log records to reach Elasticsearch
- Shows near real-time data, not real-time
</Info>

<Tip>
**Performance Tips:**
- Very long time ranges (>30 days) may affect query performance
- Unnecessary frequent refresh increases Elasticsearch load
- You can get faster results by filtering
</Tip>

## Related Resources

<CardGroup cols={2}>
  <Card title="API Traffic" icon="chart-network" href="/en/analytic/api-traffic">
    Detailed traffic analysis of all API Proxies
  </Card>
  <Card title="Tracing" icon="magnifying-glass" href="/en/analytic/tracing">
    Detailed trace and debug operations
  </Card>
  <Card title="Query Editor" icon="code" href="/en/analytic/query-editor/queries">
    Advanced query and filter definitions
  </Card>
  <Card title="Reports" icon="file-chart-line" href="/en/analytic/analytics-reports/reports">
    Customized analytics reports
  </Card>
  <Card title="API Traffic Log Settings" icon="cog" href="/en/analytic/api-traffic-log-settings">
    Log record configurations
  </Card>
  <Card title="Analytics Engine" icon="chart-pie" href="/en/concepts/core-components/analytics-engine">
    Analytics architecture and components
  </Card>
</CardGroup>


