---
title: "Distributed Cache"
description: "You can create and configure distributed cache servers for Apinizer. Cache servers can run in independent namespaces from Gateway pods, providing flexible infrastructure management. You can configure both managed and remote cache deployments."
---

<Info>
Distributed Cache is Apinizer's cache infrastructure that stores shared data such as throttling, quota, OAuth2 tokens, and load balancing information. Cache servers can now run in separate Kubernetes namespaces from Gateway pods, allowing for more flexible infrastructure management.
</Info>

## Cache Server Overview

Cache Server (`apinizer-cache`) is the environment where cache values required in Apinizer are stored. It uses Hazelcast technology for distributed caching and can be managed by Apinizer or connected to an existing remote cache deployment.

<Info>
**Namespace Independence:**

Cache Server pods can now run in a different Kubernetes namespace than Gateway pods. This provides more flexible infrastructure management and allows you to separate Gateway and Cache workloads. Gateway pods can access cache servers in other namespaces using Kubernetes service discovery (e.g., `http://cache-http-service.apinizer-cache.svc.cluster.local:8090`).
</Info>

## Cache Server Configuration

<img src="/images/admin/server-management/cache-server.png" alt="cache" width="1000" />

## Deployment Type Selection

When creating a Cache Server, you need to select the deployment type:

### Managed by Apinizer

Apinizer will automatically create and manage the cache deployment using Kubernetes API. Apinizer will create namespace, deployment, service, and all required Kubernetes resources automatically.

**Use this option when:**
- You want Apinizer to manage the entire cache lifecycle
- You need automatic resource provisioning and management
- You want simplified cache server management

### Remote Cache

Connect to an existing cache pod that was deployed manually via YAML. Apinizer will only register the connection details without managing the deployment.

**Use this option when:**
- You have an existing cache deployment managed outside Apinizer
- You need custom cache configurations not supported by Apinizer
- You want to use a cache server deployed by another system

<Warning>
**Remote Cache Requirements:**

Make sure your cache pod is running and accessible. Apinizer will only register the connection details without managing the deployment. You are responsible for maintaining the remote cache deployment.
</Warning>

## Namespace Configuration

<Info>
**Important:** The namespace configuration cannot be changed after the cache server is created. Make sure to select the correct namespace during creation.
</Info>

### Create New Namespace

When creating a new namespace, you can specify a custom namespace name. The namespace must comply with RFC 1123 DNS label standards:

- Must be between 3 and 63 characters
- Only lower case alphanumeric characters (a-z, 0-9) or hyphens (-) are allowed
- Must start and end with a lower case alphanumeric character
- Examples: `my-namespace`, `prod-env`, `123-abc`

### Use Existing Namespace

You can select an existing Kubernetes namespace where the cache server will be deployed. This is useful when:
- You want to reuse an existing namespace
- You have namespace management policies that require specific namespaces
- You want to deploy cache servers in a namespace managed by another system

<Info>
**Namespace Independence:**

Cache servers can run in namespaces different from Gateway pods. This allows you to:
- Separate Gateway and Cache workloads for better resource management
- Apply different security policies to Gateway and Cache namespaces
- Scale Gateway and Cache independently
- Use dedicated namespaces for cache infrastructure

Gateway pods can access cache servers in other namespaces using Kubernetes service discovery format: `http://service-name.namespace.svc.cluster.local:port`
</Info>

## Cache Management API Configuration

Cache Management API URLs define how API Manager and Gateway will communicate with the Cache Server application. You can configure multiple API URLs for high availability scenarios.

### Single API URL Configuration

For basic setups, configure a single Cache Management API URL:

**Format:** `http://cache-http-service.namespace.svc.cluster.local:8090`

**Example:**
- `http://cache-http-service.apinizer-cache.svc.cluster.local:8090`
- `http://cache-http-service.prod.svc.cluster.local:8090`

### Multiple API URL Configuration

You can configure multiple Cache Management API URLs for high availability. Each URL can have:
- **Name:** A descriptive name for the API URL
- **Health Check Address:** The address used for health checks

**Use cases:**
- High availability deployments across multiple namespaces
- Load balancing between multiple cache clusters
- Disaster recovery scenarios

<Info>
**Cross-Namespace Communication:**

When Gateway pods and Cache pods are in different namespaces, use the Kubernetes service discovery format:
`http://service-name.namespace.svc.cluster.local:port`

This allows Gateway pods to access cache servers regardless of their namespace location.
</Info>

## Managed Mode Configuration

When **Managed by Apinizer** is selected, Apinizer will create and manage all Kubernetes resources for the cache server.

### Resource Configuration

| Field | Description |
|------|----------|
| **Replica Count** | The number of cache pods. Equivalent to the replicaSet in the Kubernetes Cluster. |
| **CPU** | The maximum number of CPU cores the pod will use. |
| **Memory** | The maximum memory value the pod will use. |
| **Memory Unit** | The unit of the value required for memory is selected; MB, GB. |

**Recommended Values:**

| CPU | Memory Size |
|-----|---------------|
| 1   | 2GB + Estimated Cache Size |
| 2   | 4GB + Estimated Cache Size |
| 4   | 6GB + Estimated Cache Size |
| 8   | 10GB + Estimated Cache Size |

<Info>
You can reduce memory requirement per thread by using values like `-Xss256k` or `-Xss128k` in Java Options.
</Info>

### Kubernetes Service Configuration

You can configure Kubernetes services to expose the Cache Server application:

**Service Options:**
- **Create Kubernetes Service:** Enable to create a Kubernetes Service for Cache Server access
- **Service Name:** The name of the Kubernetes Service (default: `cache-server-service`)
- **Service Type:** 
  - **ClusterIP:** Default type. Service is only accessible within the cluster. Best for internal communication between API Manager/Gateway and Cache Server.
  - **NodePort:** Service is accessible via a specific port on each node (30000-32767 range)

<Warning>
**Service Deletion:**

If you disable Kubernetes Service creation, the previously created Kubernetes Service will be deleted from Kubernetes. Make sure this is what you want before disabling.
</Warning>

### Additional Variables

Default and optional variables and their values to be run in the pod are defined.

**Tomcat Settings:**

| Variable | Description | Default | Recommended Values by CPU |
|----------|----------|---------|-------------------------------|
| `SERVER_TOMCAT_MAX_THREADS` | Maximum concurrent requests Tomcat can handle | 1024 | 1 CPU: 256, 2 CPU: 1024, 4 CPU: 2048, 8 CPU: 4096 |
| `SERVER_TOMCAT_MIN_SPARE_THREADS` | Minimum thread count Tomcat will always keep ready | 512 | 1 CPU: 128, 2 CPU: 256, 4 CPU: 512, 8 CPU: 1024 |
| `SERVER_TOMCAT_ACCEPT_COUNT` | Maximum number of connections that can wait in queue when all threads are busy | 512 | 1 CPU: 256, 2 CPU: 512, 4 CPU: 1024, 8 CPU: 2048 |
| `SERVER_TOMCAT_MAX_CONNECTIONS` | Maximum connection count Tomcat can accept simultaneously | 8192 | 1 CPU: 2048, 2 CPU: 4096, 4 CPU: 8192, 8 CPU: 16384 |
| `SERVER_TOMCAT_CONNECTION_TIMEOUT` | Connection timeout in milliseconds | 20000 (20 seconds) | - |
| `SERVER_TOMCAT_KEEPALIVE_TIMEOUT` | Keep-alive connection timeout in milliseconds | 60000 (60 seconds) | - |
| `SERVER_TOMCAT_MAX_KEEPALIVE_REQUESTS` | Maximum number of requests that can be processed on a keep-alive connection | 10000 | - |
| `SERVER_TOMCAT_PROCESSOR_CACHE` | Maximum number of processors cached in processor cache | 512 | - |

**Hazelcast Settings:**

| Variable | Description | Default |
|----------|----------|------------|
| `HAZELCAST_CLIENT_SMART` | Whether the Hazelcast client will use smart routing | true |
| `HAZELCAST_IO_WRITE_THROUGH` | Hazelcast write-through mode enabled/disabled | false |
| `HAZELCAST_MAP_LOAD_CHUNK_SIZE` | Chunk size used when loading Hazelcast map | 10000 |
| `HAZELCAST_MAP_LOAD_BATCH_SIZE` | Batch size used when loading Hazelcast map | 10000 |
| `HAZELCAST_MAPCONFIG_BACKUPCOUNT` | How many backup copies of Hazelcast map data will be stored | 1 |
| `HAZELCAST_MAPCONFIG_READBACKUPDATA` | Whether to read from backup copies | false |
| `HAZELCAST_MAPCONFIG_ASYNCBACKUPCOUNT` | Number of asynchronous backup copies | 0 |
| `HAZELCAST_PARTITION_COUNT` | Hazelcast partition count | 271 |
| `HAZELCAST_OPERATION_RESPONSEQUEUE_IDLESTRATEGY` | Hazelcast operation response queue idle strategy (block/backoff) | block |
| `HAZELCAST_OPERATION_THREAD_COUNT` | Hazelcast operation thread count for EntryProcessor performance | 8 (CPU core count) |
| `HAZELCAST_OPERATION_GENERIC_THREAD_COUNT` | Hazelcast generic operation thread count for background tasks | 4 (CPU core count / 2) |
| `HAZELCAST_SERIALIZATION_USE_NATIVE_BYTE_ORDER` | Use native byte order for serialization (performance optimization) | true |
| `HAZELCAST_MAX_NO_HEARTBEAT_SECONDS` | Maximum heartbeat absence duration before marking member as dead (seconds) | 300 |
| `HAZELCAST_HEARTBEAT_INTERVAL_SECONDS` | Heartbeat interval between cluster members (seconds) | 5 |
| `HAZELCAST_MASTER_CONFIRMATION_INTERVAL_SECONDS` | Master confirmation interval (seconds) | 30 |
| `HAZELCAST_SOCKET_KEEP_ALIVE` | TCP socket keep-alive enabled | true |
| `HAZELCAST_SOCKET_NO_DELAY` | TCP_NODELAY enabled (low latency for small packets) | true |
| `HAZELCAST_OPERATION_CALL_TIMEOUT_MILLIS` | Operation call timeout in milliseconds | 60000 (60 seconds) |
| `HAZELCAST_OPERATION_BACKUP_TIMEOUT_MILLIS` | Backup operation timeout in milliseconds | 5000 (5 seconds) |
| `HAZELCAST_MAP_WRITE_DELAY_SECONDS` | Write-behind delay in seconds | 5 |
| `HAZELCAST_MAP_WRITE_BATCH_SIZE` | Write-behind batch size | 100 |
| `HAZELCAST_MAP_WRITE_COALESCING` | Write-behind coalescing enabled | true |
| `HAZELCAST_MAP_WRITE_BEHIND_QUEUE_CAPACITY` | Write-behind queue capacity | 100000 |
| `HAZELCAST_SPLITBRAIN_PROTECTION_ENABLED` | Split-brain protection enabled (for 3+ node clusters) | false |
| `HAZELCAST_SPLITBRAIN_QUORUM_SIZE` | Minimum quorum size for split-brain protection | 2 |
| `HAZELCAST_CP_MEMBER_COUNT` | CP Subsystem member count (0 = disabled) | 0 |
| `HAZELCAST_CP_GROUP_SIZE` | CP Subsystem group size | 3 |
| `HAZELCAST_CP_SESSION_TTL_SECONDS` | CP Subsystem session TTL (seconds) | 300 |
| `HAZELCAST_CP_SESSION_HEARTBEAT_SECONDS` | CP Subsystem session heartbeat interval (seconds) | 5 |
| `HAZELCAST_MERGE_BATCH_SIZE` | Merge policy batch size | 100 |
| `CACHE_SERVICE_NAME` | Service name required for Cache to access other cache pods via kubernetes | cache-hz-service |
| `CACHE_QUOTA_TIMEZONE` | Timezone for resetting daily quota information in cache (e.g., +03:00) | 00:00 |
| `CACHE_LAZY_MODE` | If cache pods should not try to load database values at once on first startup, set to "lazy" | eager |
| `METRICS_ENABLED` | Whether metric collection feature is enabled | false |

<Warning>
**HAZELCAST_OPERATION_RESPONSEQUEUE_IDLESTRATEGY**

If you set this parameter to "backoff": The pod will continuously use 90-100% of the CPU limit. This may provide 5-10% performance increase but consumes the CPU resource limit of the Cache pod.
</Warning>

<Info>
**CACHE_QUOTA_TIMEZONE:**

Daily quota information is also stored in cache. Daily quota information is reset according to UTC timezone. If you want the start time of the daily changing quota to be reset according to your local time, you can add the `CACHE_QUOTA_TIMEZONE` value to additional variables. The value added here must be written in the format "+03:00".
</Info>

<Info>
**CACHE_LAZY_MODE:**

If you do not want cache pods to try to load database values at once on first startup, the `CACHE_LAZY_MODE` value can be set to "lazy". In this case, priority is given to opening the pod, and values can continue to be loaded after the pod is opened. It is recommended to enter this value if there are a large number of records in the database.
</Info>

### Host Alias Configuration

Configure host aliases for the cache server. Host aliases allow you to map IP addresses to hostnames.

**Use cases:**
- Resolve hostnames that are not in DNS
- Map internal IP addresses to friendly hostnames
- Configure custom hostname resolution

**Example Usage:**

| IP Address | Host Names |
|------------|--------------|
| 10.10.10.10 | alias_name, other_alias_name |

### Node Name List Configuration

Configure which Kubernetes nodes the cache server pods should be scheduled on. If no nodes are selected, pods can be scheduled on any node.

**Use cases:**
- Schedule cache pods on specific high-memory nodes
- Isolate cache workloads to dedicated nodes
- Ensure cache pods run on nodes with SSD storage

## Remote Mode Configuration

When **Remote Cache** is selected, you need to configure the connection details for the existing cache deployment.

### Basic Information

| Field | Description |
|------|----------|
| **Name** | A descriptive name for the cache server configuration |
| **Description** | Optional description for the cache server |
| **Cache Management API URL** | The health check address of your cache server. Example: `http://cache-http-service.prod.svc.cluster.local:8090` |

### Connection Testing

You can test the connection to the remote cache server before saving the configuration. The test will verify:
- Network connectivity to the cache server
- Health check endpoint accessibility
- API response validation

<Info>
**Remote Cache Requirements:**

Make sure your cache pod is running and accessible before registering it as a remote cache. Apinizer will only register the connection details without managing the deployment.
</Info>

## Cache Server Operations

### Creating a Cache Server

<Steps>
  <Step title="Select Deployment Type">
    Choose between **Managed by Apinizer** or **Remote Cache** based on your requirements.
  </Step>

  <Step title="Configure Namespace">
    Select an existing namespace or create a new one. Remember that namespace cannot be changed after creation.
  </Step>

  <Step title="Configure Cache Management API">
    Configure one or more Cache Management API URLs for API Manager and Gateway communication.
  </Step>

  <Step title="Configure Resources (Managed Mode Only)">
    If using Managed mode, configure replica count, CPU, memory, and additional variables.
  </Step>

  <Step title="Save Configuration">
    Save the cache server configuration. For Managed mode, Apinizer will create the necessary Kubernetes resources.
  </Step>
</Steps>

### Updating Cache Server

You can update various aspects of the cache server configuration:

- **Basic Information:** Name and description
- **Resource Configuration:** Replica count, CPU, memory (Managed mode only)
- **Additional Variables:** Environment variables and Java options
- **Kubernetes Service Configuration:** Service type and settings (Managed mode only)
- **Host Aliases:** Host alias mappings
- **Node Name List:** Pod scheduling preferences
- **Cache Management API Settings:** API URL configurations

<Warning>
**Namespace Change:**

The namespace cannot be changed after the cache server is created. If you need to change the namespace, you must delete and recreate the cache server configuration.
</Warning>

### Deleting a Cache Server

When you delete a cache server:
- All configurations related to this cache server will be deleted
- For Managed mode, Kubernetes resources (deployments, services) will be removed
- The deleted Cache Server cannot be restored

<Danger>
**Warning:** When the deletion operation is completed, Gateway pods using this cache server will lose access to the cache. Make sure to update Gateway configurations before deleting the cache server.
</Danger>

## Best Practices

### Namespace Management

- Use dedicated namespaces for cache infrastructure when possible
- Follow naming conventions for namespaces (lowercase, alphanumeric, hyphens)
- Consider namespace resource quotas for cache pods

### High Availability

- Configure multiple Cache Management API URLs for redundancy
- Use multiple cache pod replicas for fault tolerance
- Distribute cache pods across different Kubernetes nodes

### Performance Optimization

- Configure appropriate CPU and memory based on cache size requirements
- Use `CACHE_LAZY_MODE=lazy` for large databases
- Tune Hazelcast parameters based on your workload
- Monitor cache metrics to optimize resource allocation

### Security

- Use ClusterIP services for internal communication
- Configure proper network policies for cross-namespace access
- Use TLS/HTTPS for cache management API when possible
- Regularly update cache server images

<Info>
For more information about cache architecture and usage, see the [Cache Component](/en/concepts/core-components/cache-component) page.
</Info>
