---
title: "Kapasite Planlama"
description: "Sistem, network ve altyapı yöneticileri için kapsamlı kapasite planlama rehberi: trafik tahmini, donanım gereksinimleri, ağ yapılandırması ve kurulum öncesi kararlar"
---

Kapasite planlama, Apinizer platformunun başarılı bir şekilde kurulması ve çalıştırılması için gerekli kaynakların belirlenmesi sürecidir. Bu sayfa, **sistem yöneticileri**, **network yöneticileri** ve **altyapı ekipleri** için hazırlanmış kapsamlı bir rehberdir.

## Kapasite Planlama Süreci

Kapasite planlama yaparken aşağıdaki faktörler göz önünde bulundurulmalıdır:

### Trafik Tahmini

Trafik tahmini, kapasite planlamanın temelini oluşturur. Aşağıdaki noktalar değerlendirilmelidir:

* **Beklenen API çağrı sayısı**: Günlük ve saatlik bazda beklenen API çağrı hacmi belirlenmelidir
* **Peak trafik tahmini**: En yüksek trafik dönemlerindeki (örneğin kampanya dönemleri, özel günler) trafik hacmi tahmin edilmelidir
* **Trafik büyüme projeksiyonu**: Gelecekteki trafik artışı için projeksiyon yapılmalıdır
* **Mevsimsel değişiklikler**: Yıl içindeki mevsimsel trafik değişimleri göz önünde bulundurulmalıdır

### Deployment Modeli

Apinizer'ın kurulacağı deployment modeli, kaynak gereksinimlerini doğrudan etkiler. Mevcut seçenekler:

* **Topoloji 1: Test ve PoC**: Tüm bileşenlerin tek sunucuda çalıştığı basit kurulum modeli
* **Topoloji 2: Profesyonel Kurulum**: Bileşenlerin farklı sunucularda dağıtıldığı model
* **Topoloji 3: Yüksek Erişilebilirlik**: Yüksek erişilebilirlik için kümeleme yapılan model
* **Topoloji 4: Bölgeler Arası Dağıtım**: Global dağılım, coğrafi yedekleme

Detaylı bilgi için [Deployment Modelleri](/tr/apinizer-anlama/deployment/deployment-modelleri) sayfasına bakabilirsiniz.

### Yüksek Erişilebilirlik

Kritik iş uygulamaları için yüksek erişilebilirlik gereksinimleri planlanmalıdır:

* **Uptime gereksinimleri**: Sistemin ne kadar süre kesintisiz çalışması gerektiği belirlenmelidir (genellikle %99.9+)
* **Failover stratejisi**: Bir bileşen arızalandığında trafiğin nasıl yönlendirileceği planlanmalıdır
* **Disaster recovery planı**: Büyük çaplı arıza durumlarında sistemin nasıl kurtarılacağı planlanmalıdır

### Büyüme Planı

Kapasite planlaması, sadece mevcut gereksinimleri değil, gelecekteki büyümeyi de kapsamalıdır:

* **Kısa vadeli gereksinimler**: 6 aylık dönem için gereken kaynaklar
* **Orta vadeli gereksinimler**: 1-2 yıllık dönem için planlanan kaynaklar
* **Uzun vadeli gereksinimler**: 3 yıl ve üzeri için öngörülen kaynak gereksinimleri


## Tier Bazlı Kapasite ve Donanım Gereksinimleri

Aşağıdaki tablolar, trafik seviyesine göre (Tier 1, 2, 3) veri büyüklüğü ve donanım gereksinimlerini özetlemektedir.

### Trafik Kategorileri

| Tier | Trafik Seviyesi | Kullanım Amacı |
|------|----------------|----------------|
| **Tier 1** | < 100K istek/gün | Test/POC ortamları |
| **Tier 2** | 100K - 5M istek/gün | Production ortamları |
| **Tier 3** | > 5M istek/gün | Enterprise production (8 core ile günlük 20M+ istek desteklenir) |

### Worker Nodes (API Gateway)

Worker node'ları API trafiğini işleyen ana bileşenlerdir. Aşağıdaki tablo, gerçek benchmark testlerine dayalı performans verilerini içermektedir.

| Özellik | Tier 1 | Tier 2 | Tier 3 |
|---------|--------|--------|--------|
| **CPU** | 2 core | 4 core | 8 core |
| **RAM** | 2 GB | 4 GB | 8 GB |
| **Node Sayısı** | 1 | 2 | 4 |
| **IOPS** | 1,000 | 3,000 | 5,000+ |
| **IO Threads** | 2 | 4 | 16 |

#### Benchmark Performans Sonuçları

<Warning>
  **Önemli**: Aşağıdaki performans verileri tahmini değerlerdir ve birçok parametreye göre değişkenlik gösterebilir. Bu değerler, backend servisin hızlı yanıt verdiği (network gecikmesi minimal) ideal koşullarda ölçülmüştür. Gerçek production ortamlarında performans şu faktörlere göre değişiklik gösterebilir:
  
  * **Network latency**: Backend servise olan network gecikmesi
  * **Backend API performansı**: Backend servisin yanıt süresi ve işlem kapasitesi
  * **Politika karmaşıklığı**: Gateway üzerine eklenen politikaların sayısı ve karmaşıklığı
  * **İstek gövdesi boyutu**: Büyük payload'lar daha fazla işlem gücü gerektirir
  * **Eş-zamanlı yük deseni**: Trafiğin dağılımı ve peak anları
  * **Sistem kaynakları**: CPU, RAM ve disk I/O kullanımı
  
  Bu nedenle production ortamları için mutlaka kendi trafik desenlerinize ve altyapınıza göre performans testleri yapılmalıdır.
</Warning>

Aşağıdaki performans verileri, eş-zamanlı thread yükleri altında gerçek test ortamında ölçülmüştür. Testler, backend servisin hızlı yanıt verdiği (network gecikmesi minimal) ideal koşullarda yapılmıştır.

**2 Core / 2 GB RAM Konfigürasyonu (Tier 1 - Test/POC):**
* **GET İstekleri**: 
  - 50 thread: ~2.200 reqs/sec (ortalama 22ms)
  - 100 thread: ~2.200 reqs/sec (ortalama 45ms)
  - 250 thread: ~2.100 reqs/sec (ortalama 119ms)
* **POST İstekleri (5KB gövde)**:
  - 50 thread: ~1.900 reqs/sec (ortalama 26ms)
  - 100 thread: ~1.800 reqs/sec (ortalama 56ms)
  - 250 thread: ~1.500 reqs/sec (ortalama 170ms)

**4 Core / 4 GB RAM Konfigürasyonu (Tier 2 - Production):**
* **GET İstekleri**: 
  - 50 thread: ~8.000 reqs/sec (ortalama 6ms)
  - 500 thread: ~6.700 reqs/sec (ortalama 73ms)
  - 1.000 thread: ~6.700 reqs/sec (ortalama 147ms)
* **POST İstekleri (5KB gövde)**:
  - 50 thread: ~7.300 reqs/sec (ortalama 6ms)
  - 500 thread: ~7.100 reqs/sec (ortalama 69ms)
  - 1.000 thread: ~7.000 reqs/sec (ortalama 141ms)

**8 Core / 8 GB RAM Konfigürasyonu (Tier 3 - Enterprise):**
* **GET İstekleri**: 
  - 50 thread: ~15.400 reqs/sec (ortalama 3ms)
  - 500 thread: ~15.600 reqs/sec (ortalama 31ms)
  - 1.000 thread: ~15.400 reqs/sec (ortalama 64ms)
  - 2.000 thread: ~14.800 reqs/sec (ortalama 133ms)
  - 4.000 thread: ~14.300 reqs/sec (ortalama 276ms)
  - 8.000 thread: ~11.600 reqs/sec (ortalama 655ms)
* **POST İstekleri (5KB gövde)**:
  - 50 thread: ~13.400 reqs/sec (ortalama 3ms)
  - 500 thread: ~13.600 reqs/sec (ortalama 36ms)
  - 1.000 thread: ~13.500 reqs/sec (ortalama 73ms)
  - 2.000 thread: ~13.200 reqs/sec (ortalama 150ms)
  - 4.000 thread: ~12.800 reqs/sec (ortalama 309ms)
  - 8.000 thread: ~11.100 reqs/sec (ortalama 701ms)
* **POST İstekleri (50KB gövde)**:
  - 50 thread: ~4.700 reqs/sec (ortalama 10ms)
  - 500 thread: ~3.500 reqs/sec (ortalama 142ms)
  - 1.000 thread: ~3.000 reqs/sec (ortalama 326ms)
  - 2.000 thread: ~2.800 reqs/sec (ortalama 710ms)

<Info>
  **Kapasite Hesaplama Örneği**: 8 core / 8 GB RAM konfigürasyonu ile günlük 20 milyon+ istek desteklenebilir. Örnek hesaplama:
  
  * **Günlük 20 milyon istek** = Ortalama ~231 reqs/sec
  * **Peak trafik** (günün %20'sinde trafiğin %60'ı): ~694 reqs/sec
  * **8 core konfigürasyonu** ile 1.000 thread'de ~15.400 reqs/sec (GET) kapasitesi mevcuttur
  * Bu nedenle 8 core ile günlük 20 milyon+ istek rahatlıkla karşılanabilir
  
  **Not**: Bu değerler tahmini olup, network latency, backend API performansı, politika karmaşıklığı ve diğer faktörlere göre değişkenlik gösterebilir. Gerçek kapasite planlaması için kendi ortamınızda performans testleri yapılmalıdır.
  
  Daha yüksek trafik gereksinimleri için yatay ölçeklendirme (Kubernetes üzerinden ek worker node'lar eklenerek) yapılabilir.
</Info>

<Info>
  **Önemli Notlar**:
  
  * **Eş-zamanlı Thread vs İstek**: Eş-zamanlı thread sayısı ile anlık istek sayısı farklı kavramlardır. Bir thread, belirli bir süre içinde birden fazla istek yapabilir. Gateway'ler genellikle stateless çalıştığı için eş-zamanlı istek sayısı ve latency ölçümü daha anlamlıdır.
  
  * **Performans Etkileyen Faktörler**: 
    - Backend servisin yanıt süresi
    - Network gecikmesi
    - Gateway üzerine eklenen politikaların karmaşıklığı ve sayısı
    - İstek gövdesi boyutu (büyük payload'lar daha fazla işlem gücü gerektirir)
  
  * **Ölçeklendirme**: Dikey ölçeklendirmenin bir sınırı vardır. Kabul edilebilir yanıt sürelerine sahip daha fazla eş-zamanlı kullanıcıyı desteklemek için yatay ölçeklendirme (Kubernetes üzerinden kolayca yapılabilir) veya dikey + yatay kombinasyonu düşünülmelidir.
  
  * **Politika Etkisi**: Gateway'e eklenen her politika performansı etkiler. Örneğin "Basic Authentication" gibi basit politikalar minimal etki yaparken, "Content Filtering" gibi işlem gücü yüksek politikalar veya "LDAP Authentication" gibi dış bağlantı gerektiren politikalar daha fazla performans etkisi yaratır.
</Info>

#### Worker Node Konfigürasyon Ayarları

Worker node'ların performansı, aşağıdaki konfigürasyon ayarlarına bağlıdır. Bu ayarlar, API Gateway Ortam Ayarlama ekranından yapılabilir:

**Tier 1 (2 Core / 2 GB RAM) Önerilen Ayarlar:**
* **IO Threads**: 2
* **Routing Connection Pool - Min Thread Count**: 512
* **Routing Connection Pool - Max Thread Count**: 2.048
* **Routing Connection Pool - Http Max Connections**: 4.096
* **Routing Connection Pool - Max Connections Per Route**: 2.048
* **Routing Connection Pool - Max Connections Total**: 4.096
* **Elasticsearch Client - IO Thread Count**: 16
* **Elasticsearch Client - Max Connections Per Route**: 64
* **Elasticsearch Client - Max Connections Total**: 128

**Tier 2 (4 Core / 4 GB RAM) Önerilen Ayarlar:**
* **IO Threads**: 4
* **Routing Connection Pool - Min Thread Count**: 1.024
* **Routing Connection Pool - Max Thread Count**: 4.096
* **Routing Connection Pool - Http Max Connections**: 8.192
* **Routing Connection Pool - Max Connections Per Route**: 4.096
* **Routing Connection Pool - Max Connections Total**: 8.192
* **Elasticsearch Client - IO Thread Count**: 32
* **Elasticsearch Client - Max Connections Per Route**: 64
* **Elasticsearch Client - Max Connections Total**: 128

**Tier 3 (8 Core / 8 GB RAM) Önerilen Ayarlar:**
* **IO Threads**: 16
* **Routing Connection Pool - Min Thread Count**: 1.024
* **Routing Connection Pool - Max Thread Count**: 8.192
* **Routing Connection Pool - Http Max Connections**: 8.192
* **Routing Connection Pool - Max Connections Per Route**: 4.096
* **Routing Connection Pool - Max Connections Total**: 8.192
* **Elasticsearch Client - IO Thread Count**: 32
* **Elasticsearch Client - Max Connections Per Route**: 128
* **Elasticsearch Client - Max Connections Total**: 256

**JVM Parametreleri:**
* `-server -XX:MaxRAMPercentage=90`

<Warning>
  **Dikkat**: Bu performans verileri, backend servisin hızlı yanıt verdiği ve network gecikmesinin minimal olduğu ideal koşullarda ölçülmüştür. Gerçek production ortamlarında, backend servisin yanıt süresi, network gecikmesi ve eklenen politikalar performansı önemli ölçüde etkileyebilir. Production ortamları için mutlaka kendi trafik desenlerinize göre performans testleri yapılmalıdır.
</Warning>

### Manager Nodes

Manager node'ları, konfigürasyonların yapıldığı web arayüzünü sağlar. Günlük trafik yüküne bağlı olarak değişmez; konfigürasyon yönetimi ve arayüz erişimi için kullanılır. Standalone kurulum için tek node yeterlidir, production ortamları için yüksek erişilebilirlik amacıyla en az 2 node ile HA kurulumu önerilir.

### MongoDB Replica Set

MongoDB, Apinizer'ın konfigürasyon veritabanıdır. API proxy tanımları, politika konfigürasyonları ve metadata bilgilerini saklar. Günlük trafik yüküne bağlı olarak değişmez; gereksinimler, API proxy sayısı ve konfigürasyon karmaşıklığına göre belirlenir. 

<Warning>
  **Kritik**: MongoDB mutlaka **Replica Set** olarak yapılandırılmalıdır. Tek node dahi olsa replica set olarak kurulmalıdır. Standalone instance kullanılmamalıdır.
</Warning>

### Elasticsearch Cluster

Elasticsearch, log ve analitik verilerini saklar.

| Özellik | Tier 1 | Tier 2 | Tier 3 |
|---------|--------|--------|--------|
| **CPU** | 4 core | 8 core | 16 core |
| **RAM** | 16 GB | 32 GB | 64 GB |
| **Disk (Hot)** | 500 GB SSD | 2 TB SSD | 5+ TB SSD |
| **Disk (Warm)** | 1 TB HDD | 3 TB HDD | 10+ TB HDD |
| **Network** | 1 Gbps | 1-10 Gbps | 10+ Gbps |
| **Node Sayısı** | 3 (min) | 3-5 | 5+ |
| **Shard/Index** | 1-2 | 3-5 | 5+ |
| **Günlük Log** | < 10 GB | 10-100 GB | > 100 GB |
| **Aylık Log** | ~300 GB | ~1.5 TB | ~6 TB+ |
| **Yıllık Log (Retention)** | ~3.6 TB | ~18 TB | ~72 TB+ |

<Info>
  **Disk Stratejisi**: Hot tier için SSD, Warm/Cold tier için HDD kullanılması önerilir. Bu, maliyet optimizasyonu sağlar.
</Info>

### Cache Cluster (Hazelcast)

Cache Cluster, Apinizer'ın distributed cache altyapısıdır ve kritik performans verilerini saklar. Response cache, routing load balancer bilgileri, rate limit sayaçları ve diğer performans kritik veriler burada tutulur. Cache boyutu, cache'lenecek veri miktarına göre belirlenir ve günlük trafik sayısından ziyade cache'lenecek veri hacmi önemlidir.

| Özellik | Küçük Cache | Orta Cache | Büyük Cache |
|---------|-------------|------------|-------------|
| **Cache Boyutu** | 32 GB | 64-128 GB | 256+ GB |
| **CPU** | 4 core | 8 core | 16 core |
| **RAM** | 32 GB | 64-128 GB | 256+ GB |
| **Disk** | 100 GB SSD | 200 GB SSD | 500 GB SSD |
| **Network** | 1 Gbps | 1-10 Gbps | 10 Gbps |
| **Node Sayısı** | 3 (min) | 3-5 | 5+ |

## Toplam Kaynak Hesaplama Örneği

### Senaryo: Orta Ölçekli Production (Tier 2)

**Worker Nodes:**
* 3 node × (4 CPU + 4 GB RAM + 100 GB Disk) = 12 CPU + 12 GB RAM + 300 GB Disk

**Manager Nodes:**
* 2 node × (4 CPU + 16 GB RAM + 100 GB Disk) = 8 CPU + 32 GB RAM + 200 GB Disk

**MongoDB Replica Set:**
* 3 node × (8 CPU + 32 GB RAM + 500 GB Disk) = 24 CPU + 96 GB RAM + 1.5 TB Disk

**Elasticsearch Cluster:**
* 3 node × (8 CPU + 32 GB RAM + 2 TB Disk) = 24 CPU + 96 GB RAM + 6 TB Disk

**Cache Cluster:**
* 3 node × (8 CPU + 32 GB RAM + 200 GB Disk) = 24 CPU + 96 GB RAM + 600 GB Disk

**TOPLAM:**
* **CPU**: 92 core
* **RAM**: 312 GB
* **Disk**: ~8.6 TB

## Kapasite Planlama Checklist

- [ ] Trafik seviyesi belirlendi (Tier 1/2/3)
- [ ] Günlük/saatlik/peak trafik tahmini yapıldı
- [ ] Trafik büyüme projeksiyonu hazırlandı
- [ ] Worker node gereksinimleri hesaplandı (CPU, RAM, Disk, Network, Node sayısı)
- [ ] Manager node gereksinimleri belirlendi (Standalone veya HA)
- [ ] MongoDB veri büyüklüğü tahmin edildi (API Proxy sayısı, Audit Log)
- [ ] Elasticsearch log verisi tahmin edildi (günlük/aylık/yıllık retention)
- [ ] Cache cluster boyutu belirlendi (cache'lenecek veri hacmine göre)
- [ ] Network bandwidth gereksinimleri hesaplandı
- [ ] Toplam kaynak hesaplaması yapıldı (CPU, RAM, Disk)
- [ ] Node sayıları belirlendi (HA ve ölçeklendirme için)
- [ ] Deployment modeli seçildi (Topoloji 1/2/3/4)


<Note>
  **Önemli**: Bu rehber başlangıç için bir kılavuzdur. Gerçek gereksinimler, trafik desenleri, API karmaşıklığı ve politika sayısına göre değişebilir. Production ortamları için mutlaka performans testleri yapılmalıdır.
</Note>
