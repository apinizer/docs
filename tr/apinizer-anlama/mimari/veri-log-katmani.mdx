---
title: "Veri Log Katmanı"
description: 'Database Strategy, Analytics Storage, Why External DB?, Capacity planning'
---

Apinizer Platformu'nda veri ve log katmanı, sistemin veri saklama ve loglama ihtiyaçlarını karşılar. Bu katman, API trafiği logları, analitik veriler, konfigürasyon bilgileri ve diğer sistem verilerinin saklanması ve yönetilmesinden sorumludur.

Apinizer platformu, farklı veri türleri için optimize edilmiş depolama katmanları kullanır. Bu katmanlar, konfigürasyon verilerinden analitik log'lara kadar geniş bir yelpazede veri yönetimi sağlar.

## Veri Katmanları

### MongoDB - Konfigürasyon ve Metadata

MongoDB, Apinizer platformunun konfigürasyon verilerini ve metadata'yı saklamak için kullanılır.

<CardGroup cols={2}>
  <Card title="Konfigürasyon Verileri" icon="gear">
    * API Proxy tanımları
    * Politika konfigürasyonları
    * Ortam (Environment) ayarları
    * Kullanıcı ve rol tanımları
    * Bağlantı (Connection) bilgileri
  </Card>
  <Card title="Metadata" icon="database">
    * API Proxy versiyonları
    * Deployment geçmişi
    * Kullanıcı oturumları
    * Token kayıtları (OAuth2)
    * Audit log kayıtları
  </Card>
</CardGroup>

**MongoDB Gereksinimleri:**
* Replica Set yapılandırması (tek node dahi olsa)
* Standalone Instance kullanılmamalıdır
* Yüksek erişilebilirlik için en az 3 node önerilir
* Veri güvenliği için düzenli yedekleme

### Elasticsearch - Log ve Analitik Veriler

Elasticsearch, API trafik log'ları ve analitik verilerin saklanması ve sorgulanması için kullanılır.

<CardGroup cols={2}>
  <Card title="API Traffic Logs" icon="file-lines">
    * İstek/yanıt log'ları
    * Performans metrikleri
    * Hata kayıtları
    * İstemci bilgileri
    * Endpoint kullanım istatistikleri
  </Card>
  <Card title="Analitik Veriler" icon="chart-bar">
    * Kullanım metrikleri
    * Performans analizi
    * Hata dağılımları
    * Trend analizleri
    * Raporlama verileri
  </Card>
</CardGroup>

**Elasticsearch Gereksinimleri:**
* Index lifecycle management (ILM) politikaları
* Yedekleme ve snapshot stratejileri
* Kapasite planlama ve ölçeklendirme
* Cluster health monitoring

## Neden Harici Veritabanı?

### Performans Optimizasyonu

* **Ayrı Ölçeklendirme**: Konfigürasyon ve log verileri farklı performans gereksinimlerine sahiptir
* **Özel Optimizasyonlar**: Her veritabanı kendi kullanım senaryosuna göre optimize edilebilir
* **Kaynak İzolasyonu**: Yüksek trafikli log yazma işlemleri konfigürasyon okuma/yazma işlemlerini etkilemez

### Güvenlik ve Erişim Kontrolü

* **Ayrı Erişim Politikaları**: Log verilerine erişim daha kısıtlı tutulabilir
* **Veri Maskeleme**: Hassas verilerin log'larda maskelenmesi için özel işlemler yapılabilir
* **Compliance**: Farklı veri türleri için farklı compliance gereksinimleri karşılanabilir

### Ölçeklenebilirlik

* **Horizontal Scaling**: Her veritabanı bağımsız olarak ölçeklendirilebilir
* **Kapasite Yönetimi**: Log verilerinin büyümesi konfigürasyon veritabanını etkilemez
* **Maliyet Optimizasyonu**: Her veritabanı için uygun kaynak tahsisi yapılabilir

## Veri Stratejisi

### Konfigürasyon Verileri (MongoDB)

**Veri Türleri:**
* Küçük ve sık güncellenen veriler
* İlişkisel yapılar (API Proxy, Politika, Ortam)
* Transaction gereksinimleri
* Hızlı okuma/yazma erişimi

**Strateji:**
* Replica Set ile yüksek erişilebilirlik
* Düzenli yedekleme
* Index optimizasyonu
* TTL (Time To Live) politikaları ile eski verilerin temizlenmesi

### Log ve Analitik Veriler (Elasticsearch)

**Veri Türleri:**
* Büyük hacimli, zaman serisi verileri
* Append-only yazma deseni
* Sorgu ve analiz odaklı
* Uzun süreli saklama gereksinimleri

**Strateji:**
* Index lifecycle management (ILM)
* Hot-Warm-Cold tier stratejisi
* Snapshot ve restore
* Retention politikaları
* Index rotation (günlük/haftalık)

## Kapasite Planlama

### MongoDB Kapasite Planlama

<AccordionGroup>
  <Accordion title="Veri Büyüklüğü Tahmini">
    * API Proxy sayısı: Her proxy ~10-50 KB
    * Politika sayısı: Her politika ~5-20 KB
    * Kullanıcı sayısı: Her kullanıcı ~2-5 KB
    * Audit log'lar: Günlük ~100 MB - 1 GB (kullanıma göre)
    
    **Örnek Hesaplama:**
    * 1000 API Proxy: ~50 MB
    * 500 Politika: ~10 MB
    * 1000 Kullanıcı: ~5 MB
    * 1 Yıllık Audit Log: ~36-365 GB
    
    **Toplam Tahmini:** ~100 GB - 500 GB (1 yıl için)
  </Accordion>
  
  <Accordion title="Performans Gereksinimleri">
    * **IOPS**: 1000-5000 IOPS (SSD önerilir)
    * **RAM**: Veri boyutunun %25-50'si (minimum 8 GB)
    * **CPU**: 2-4 core (replica set için)
    * **Network**: 1 Gbps (internal network)
  </Accordion>
  
  <Accordion title="Yedekleme Stratejisi">
    * Günlük tam yedekleme
    * Haftalık arşiv yedekleme
    * Aylık uzun süreli arşiv
    * Yedekleme saklama süresi: 30-90 gün
  </Accordion>
</AccordionGroup>

### Elasticsearch Kapasite Planlama

<AccordionGroup>
  <Accordion title="Veri Büyüklüğü Tahmini">
    * Günlük log hacmi: API trafiğine bağlı
    * **Düşük trafik**: 1-10 GB/gün
    * **Orta trafik**: 10-100 GB/gün
    * **Yüksek trafik**: 100 GB+/gün
    
    **Örnek Hesaplama (Orta Trafik):**
    * Günlük: 50 GB
    * Aylık: ~1.5 TB
    * Yıllık: ~18 TB (retention'a göre değişir)
    
    **Retention Politikası:**
    * Hot tier: 7-30 gün
    * Warm tier: 30-90 gün
    * Cold tier: 90-365 gün
  </Accordion>
  
  <Accordion title="Performans Gereksinimleri">
    * **Disk**: SSD (Hot tier), HDD (Warm/Cold tier)
    * **RAM**: 16-64 GB (node başına)
    * **CPU**: 4-8 core (node başına)
    * **Network**: 10 Gbps (yüksek trafik için)
    * **Shard sayısı**: Index başına 1-5 shard
  </Accordion>
  
  <Accordion title="Index Lifecycle Management">
    * **Hot Tier**: Son 7-30 gün, SSD, yüksek performans
    * **Warm Tier**: 30-90 gün, HDD, orta performans
    * **Cold Tier**: 90-365 gün, HDD, düşük performans
    * **Delete**: Retention süresi sonrası otomatik silme
  </Accordion>
</AccordionGroup>

## Veri Yönetimi Best Practices

### MongoDB Best Practices

* Replica Set kullanımı (minimum 3 node)
* Düzenli yedekleme ve restore testleri
* Index optimizasyonu ve sorgu performansı izleme
* TTL index'leri ile otomatik veri temizleme
* Connection pooling ve resource management

### Elasticsearch Best Practices

* Index template'leri ve ILM politikaları
* Shard sayısı optimizasyonu (her shard 10-50 GB)
* Snapshot stratejisi (günlük snapshot)
* Cluster health monitoring
* Query performance optimization
* Curator kullanımı ile eski index'lerin temizlenmesi

## Monitoring ve Bakım

### MongoDB Monitoring

* Replica set durumu
* Oplog boyutu ve kullanımı
* Connection sayısı
* Query performansı
* Disk kullanımı

### Elasticsearch Monitoring

* Cluster health (green/yellow/red)
* Index sayısı ve boyutları
* Shard allocation durumu
* Query performansı
* Disk kullanımı ve hot/warm/cold tier dağılımı

## Sonraki Adımlar

<CardGroup cols={2}>
  <Card title="MongoDB Kurulumu" icon="database" href="/tr/kurulum-surum-yukseltme/mongodb-kurulumu/giris">
    MongoDB kurulum adımlarını inceleyin
  </Card>
  <Card title="Elasticsearch Kurulumu" icon="magnifying-glass" href="/tr/kurulum-surum-yukseltme/elasticsearch-kurulumu/giris">
    Elasticsearch kurulum adımlarını inceleyin
  </Card>
  <Card title="Kapasite Planlama" icon="calculator" href="/tr/apinizer-anlama/sistem/kapasite-planlama">
    Detaylı kapasite planlama yapın
  </Card>
  <Card title="Yedekleme Stratejileri" icon="floppy-disk" href="/tr/kurulum-surum-yukseltme/surum-yukseltme-ve-yedekleme/mongodb-yedekleme-ve-geri-yukleme">
    Yedekleme stratejilerini öğrenin
  </Card>
</CardGroup>
